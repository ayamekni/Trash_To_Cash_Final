{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \u267b\ufe0f EcoScan Self-Supervised Learning Enhancement\n", "This notebook extends the EcoScan system with a self-supervised learning loop that leverages low-confidence predictions for self-improvement."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 1: Install Required Libraries\n", "!pip install transformers torch torchvision pillow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 2: Load Model and Processor\n", "from transformers import AutoModelForImageClassification, AutoImageProcessor\n", "from PIL import Image\n", "import torch\n", "import os\n\n", "model = AutoModelForImageClassification.from_pretrained(\"prithivMLmods/Recycling-Net-11\")\n", "processor = AutoImageProcessor.from_pretrained(\"prithivMLmods/Recycling-Net-11\")\n", "labels = model.config.id2label\n", "model.eval()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 3: Define a Self-Supervised Prediction Function\n", "def predict_with_confidence(image_path):\n", "    image = Image.open(image_path).convert(\"RGB\")\n", "    inputs = processor(images=image, return_tensors=\"pt\")\n", "    with torch.no_grad():\n", "        outputs = model(**inputs)\n", "        logits = outputs.logits\n", "        probs = torch.nn.functional.softmax(logits, dim=-1)\n", "        confidence, predicted_class = torch.max(probs, dim=-1)\n", "        return predicted_class.item(), confidence.item(), probs.squeeze().tolist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 4: Create a Pseudo-Labeled Dataset Based on Confidence\n", "pseudo_labeled_data = []\n", "image_folder = \"./unlabeled_images\"  # Replace with your folder\n", "threshold = 0.75\n\n", "for fname in os.listdir(image_folder):\n", "    if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n", "        img_path = os.path.join(image_folder, fname)\n", "        pred_label, confidence, _ = predict_with_confidence(img_path)\n", "        if confidence > threshold:\n", "            pseudo_labeled_data.append((img_path, pred_label, confidence))\n", "print(f\"Collected {len(pseudo_labeled_data)} pseudo-labeled images above {threshold*100}% confidence.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 5: Fine-tune the Model Using Pseudo-Labeled Data\n", "from torch.utils.data import Dataset, DataLoader\n", "from torchvision import transforms\n\n", "class PseudoLabelDataset(Dataset):\n", "    def __init__(self, data, transform=None):\n", "        self.data = data\n", "        self.transform = transform\n\n", "    def __len__(self):\n", "        return len(self.data)\n\n", "    def __getitem__(self, idx):\n", "        img_path, label, _ = self.data[idx]\n", "        image = Image.open(img_path).convert(\"RGB\")\n", "        if self.transform:\n", "            image = self.transform(image)\n", "        return image, label\n\n", "transform = transforms.Compose([\n", "    transforms.Resize((224, 224)),\n", "    transforms.ToTensor()\n", "])\n\n", "pseudo_dataset = PseudoLabelDataset(pseudo_labeled_data, transform=transform)\n", "pseudo_loader = DataLoader(pseudo_dataset, batch_size=16, shuffle=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 6: Self-Supervised Fine-Tuning\n", "from torch import nn, optim\n\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "model.to(device)\n", "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n", "criterion = nn.CrossEntropyLoss()\n", "model.train()\n\n", "for epoch in range(3):\n", "    total_loss = 0\n", "    for images, labels in pseudo_loader:\n", "        images = images.to(device)\n", "        labels = labels.to(device)\n", "        inputs = processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n", "        outputs = model(pixel_values=inputs['pixel_values'])\n", "        loss = criterion(outputs.logits, labels)\n", "        loss.backward()\n", "        optimizer.step()\n", "        optimizer.zero_grad()\n", "        total_loss += loss.item()\n", "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(pseudo_loader):.4f}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 2}